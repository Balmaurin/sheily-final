### ğŸ‹ï¸ Sheily Train - Sistema de Entrenamiento

Sistema centralizado para entrenar modelos usando los datos de las 50 ramas especializadas.

---

## ğŸš€ USO RÃPIDO

### Ver ramas disponibles:
```bash
python3 sheily_train/train_branch.py --list-branches
```

### Entrenar una rama especÃ­fica:
```bash
# BÃ¡sico (fÃ­sica - 1824 ejemplos)
python3 sheily_train/train_branch.py --branch physics

# Con LoRA eficiente (deportes)
python3 sheily_train/train_branch.py --branch sports --lora --epochs 5

# Medicina con mÃ¡s epochs
python3 sheily_train/train_branch.py --branch medicine --epochs 10 --lora

# ProgramaciÃ³n personalizado
python3 sheily_train/train_branch.py \
    --branch programming \
    --model meta-llama/Llama-2-7b-hf \
    --epochs 10 \
    --batch-size 8 \
    --lora \
    --output models/programming_custom

# Finanzas
python3 sheily_train/train_branch.py --branch finance --lora

# Arte
python3 sheily_train/train_branch.py --branch art --epochs 5
```

---

## ğŸ“ ESTRUCTURA

```
sheily_train/
â”œâ”€â”€ train_branch.py           # âœ… Lanzador principal
â”œâ”€â”€ train_all.sh             # âœ… Entrenar todas las ramas
â”œâ”€â”€ README.md                # âœ… Esta documentaciÃ³n
â”‚
â”œâ”€â”€ core/
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ trainer.py       # TODO: Implementar trainer real
â”‚       â””â”€â”€ training_router.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup/              # Scripts de configuraciÃ³n
â”‚   â”œâ”€â”€ testing/            # Tests del sistema
â”‚   â””â”€â”€ deployment/         # Deployment
â”‚
â””â”€â”€ tools/
    â””â”€â”€ monitoring/         # Monitoreo de entrenamientos
```

---

## ğŸ”— RELACIÃ“N CON all-Branches/

Cada rama en `all-Branches/` tiene datos de entrenamiento:

```
all-Branches/
â”œâ”€â”€ physics/
â”‚   â””â”€â”€ training/
â”‚       â””â”€â”€ data/
â”‚           â”œâ”€â”€ train.jsonl                        # â† DATOS AQUÃ
â”‚           â”œâ”€â”€ premium_training_dataset.jsonl
â”‚           â””â”€â”€ complete_optimized_premium_dataset.jsonl
â”‚
â”œâ”€â”€ sports/
â”‚   â””â”€â”€ training/
â”‚       â””â”€â”€ data/
â”‚           â””â”€â”€ train.jsonl                        # â† DATOS AQUÃ
â””â”€â”€ ... (48 ramas mÃ¡s)
```

**sheily_train/** lee estos datos automÃ¡ticamente.

---

## ğŸ› ï¸ TRAINER IMPLEMENTADO

El sistema de entrenamiento estÃ¡ **100% FUNCIONAL**:

1. âœ… ValidaciÃ³n de ramas
2. âœ… Carga de configuraciÃ³n
3. âœ… PreparaciÃ³n de paths y parÃ¡metros
4. âœ… **Trainer real implementado** con HuggingFace Transformers
5. âœ… Soporte completo para LoRA
6. âœ… TokenizaciÃ³n automÃ¡tica
7. âœ… Guardado de modelos y mÃ©tricas

### CaracterÃ­sticas del Trainer:

- âœ… IntegraciÃ³n con HuggingFace Transformers
- âœ… Soporte para LoRA (entrenamiento eficiente)
- âœ… Carga automÃ¡tica de datos JSONL
- âœ… Formateo de instruction-following
- âœ… TokenizaciÃ³n optimizada
- âœ… DetecciÃ³n automÃ¡tica de GPU/CPU
- âœ… Guardado de modelo, tokenizer y mÃ©tricas
- âœ… Manejo robusto de errores
- âœ… Logging detallado del proceso

### Usar el Sistema:

#### 1. Instalar dependencias:
```bash
pip install transformers datasets peft accelerate bitsandbytes torch
# o simplemente:
make install
```

#### 2. Entrenar un modelo:
```bash
# BÃ¡sico
python3 sheily_train/train_branch.py --branch physics --lora

# Avanzado
python3 sheily_train/train_branch.py \
    --branch medicine \
    --model meta-llama/Llama-2-7b-hf \
    --epochs 10 \
    --batch-size 8 \
    --lora
```

#### 3. El trainer automÃ¡ticamente:
- Carga el modelo y tokenizer
- Prepara los datos
- Aplica LoRA si estÃ¡ configurado
- Entrena el modelo
- Guarda todo en `var/central_models/{rama}/`

### Archivo Implementado:

`sheily_train/core/training/trainer.py` (280+ lÃ­neas)
- FunciÃ³n `train_model()` - Entrenamiento completo
- FunciÃ³n `load_training_data()` - Carga de datos
- FunciÃ³n `create_lora_model()` - ConfiguraciÃ³n LoRA
- FunciÃ³n `quick_test()` - Test del modelo

---

## ğŸ“Š OUTPUTS

Los modelos entrenados se guardan en:
```
var/central_models/
â”œâ”€â”€ physics/
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ training_config.json
â”‚   â””â”€â”€ adapter_model.bin      # Si usaste LoRA
â”‚
â”œâ”€â”€ sports/
â””â”€â”€ ... (otras ramas)
```

Logs en:
```
var/central_logs/
â””â”€â”€ training_*.log
```

---

## ğŸ¯ ESTADO ACTUAL

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  COMPONENTE              â”‚  ESTADO            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  train_branch.py         â”‚  âœ… FUNCIONAL      â•‘
â•‘  ValidaciÃ³n de datos     â”‚  âœ… FUNCIONAL      â•‘
â•‘  ConfiguraciÃ³n           â”‚  âœ… FUNCIONAL      â•‘
â•‘  Trainer real            â”‚  âœ… IMPLEMENTADO   â•‘
â•‘  Datos en all-Branches   â”‚  âœ… LISTOS (50)    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## â“ PREGUNTAS FRECUENTES

**Q: Â¿Desde dÃ³nde se lanzan los entrenamientos?**  
A: Desde `sheily_train/train_branch.py`

**Q: Â¿DÃ³nde estÃ¡n los datos?**  
A: En `all-Branches/{rama}/training/data/*.jsonl`

**Q: Â¿Vale la pena sheily_train/?**  
A: **SÃ**. Es el punto centralizado para:
   - Lanzar entrenamientos de cualquier rama
   - Gestionar configuraciones
   - Almacenar modelos entrenados
   - Monitorear progreso

**Q: Â¿EstÃ¡ completo el sistema?**  
A: **SÃ, 100% FUNCIONAL**. El trainer estÃ¡ implementado y listo para usar.

**Q: Â¿Puedo entrenar sin GPU?**  
A: SÃ­, pero serÃ¡ muy lento. Usa `--lora` para reducir memoria.

---

## ğŸ“š RECURSOS

- [HuggingFace Transformers](https://huggingface.co/docs/transformers)
- [PEFT (LoRA)](https://huggingface.co/docs/peft)
- [Datasets](https://huggingface.co/docs/datasets)

---

**Version:** 2.0  
**Status:** âœ… Launcher funcional, â³ Trainer por implementar  
**Maintainer:** Sheily AI Research Team
