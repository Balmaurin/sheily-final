# Sheily AI - Environment Variables Example
# ==========================================
# COPIAR ESTE ARCHIVO A .env Y CONFIGURAR TUS VALORES

# Modelo LLM
MODEL_NAME=meta-llama/Llama-2-7b-hf
MODEL_PATH=var/central_models/
USE_GPU=true

# Entrenamiento
BATCH_SIZE=4
LEARNING_RATE=2e-4
MAX_EPOCHS=10
USE_LORA=true

# Rutas del Proyecto
PROJECT_ROOT=/ruta/a/tu/proyecto
BRANCHES_DIR=all-Branches
OUTPUT_DIR=var/central_models

# Logging
LOG_LEVEL=INFO
LOG_DIR=var/central_logs

# API (opcional)
API_HOST=127.0.0.1
API_PORT=8000
API_WORKERS=4

# HuggingFace (opcional)
# HF_TOKEN=tu_token_de_huggingface_aqui
# HF_CACHE_DIR=var/central_cache/huggingface

# Base de Datos (opcional)
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=sheily_ai
# DB_USER=sheily
# DB_PASSWORD=tu_password_aqui

# Seguridad
# IMPORTANTE: Genera una clave única con:
# python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=CAMBIAR_POR_CLAVE_UNICA_GENERADA
DEBUG=false

# Monitoreo (opcional)
# ENABLE_TELEMETRY=false
# SENTRY_DSN=tu_sentry_dsn_aqui

# CORS (producción)
# Descomentar y configurar para permitir orígenes específicos
# CORS_ORIGINS=http://localhost:3000,https://tu-dominio.com

# Host (producción)
# En producción, puedes configurar 0.0.0.0 si es necesario
# Por defecto usa 127.0.0.1 (más seguro)
# HOST=0.0.0.0
