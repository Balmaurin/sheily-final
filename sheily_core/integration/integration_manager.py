"""
Gestor de Integración de Módulos - Sheily Core Integration
=========================================================

Gestor central de integración para el ecosistema Sheily-AI.
Proporciona enrutamiento inteligente, validación de seguridad,
health monitoring y mejora continua del sistema.

Integrado desde backup y adaptado para sheily_core/integration/
"""

import logging
from datetime import datetime
from typing import Any, Dict, List, Optional

# Usar el logger de sheily_core si está disponible
try:
    from sheily_core.logger import get_logger

    logger = get_logger(__name__)
except ImportError:
    logger = logging.getLogger(__name__)


class IntegrationManager:
    """Gestor central de integración de módulos de Sheily-AI - Versión Corregida"""

    def __init__(self, base_config: Optional[Dict[str, Any]] = None):
        """
        Inicializar gestor de integración

        Args:
            base_config: Configuración base del sistema
        """
        self.logger = logging.getLogger(__name__)
        self.config = base_config or {}
        self.initialized = False

        # Estado del sistema
        self.active_modules = {}
        self.module_health = {}
        self.integration_history = []

        # Configuración por defecto
        self.default_config = {
            "max_concurrent_queries": 10,
            "timeout_seconds": 30,
            "cache_enabled": True,
            "logging_level": "INFO",
        }

        # Combinar configuraciones
        self.effective_config = {**self.default_config, **self.config}

        # Inicializar componentes básicos
        self._initialize_basic_components()

    def _initialize_basic_components(self):
        """Inicializar componentes básicos sin dependencias problemáticas"""
        try:
            # Simulación de componentes (evita importaciones problemáticas)
            self.active_modules = {
                "knowledge_generator": {"status": "active", "health": "good"},
                "semantic_adapter": {"status": "active", "health": "good"},
                "security_manager": {"status": "active", "health": "good"},
                "error_detector": {"status": "active", "health": "good"},
            }

            self.initialized = True
            self.logger.info("IntegrationManager inicializado exitosamente")

        except Exception as e:
            self.logger.error(f"Error inicializando componentes: {e}")
            self.initialized = False

    def process_query(self, query: str, user_context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Procesar consulta de forma unificada

        Args:
            query: Consulta del usuario
            user_context: Contexto adicional del usuario

        Returns:
            Resultado procesado
        """
        if not self.initialized:
            return {
                "error": "IntegrationManager no inicializado",
                "query": query,
                "timestamp": datetime.now().isoformat(),
            }

        try:
            # Procesar consulta paso a paso
            processing_steps = []

            # 1. Validación de seguridad (simulada)
            security_check = self._validate_security(query)
            processing_steps.append({"step": "security", "result": security_check})

            if isinstance(security_check, dict) and not security_check.get("valid", True):
                return {
                    "error": "Acceso denegado",
                    "query": query,
                    "processing_steps": processing_steps,
                    "timestamp": datetime.now().isoformat(),
                }

            # 2. Adaptación semántica (simulada)
            adapted_query = self._adapt_semantic_context(query)
            processing_steps.append({"step": "semantic_adaptation", "result": adapted_query})

            # 3. Enrutamiento (simulado)
            routing_result = self._route_query(adapted_query)
            processing_steps.append({"step": "routing", "result": routing_result})

            # 4. Generación de conocimiento contextual
            domain = (
                routing_result.get("domain", "general")
                if isinstance(routing_result, dict)
                else "general"
            )
            contextual_knowledge = self._generate_contextual_knowledge(adapted_query, domain)
            processing_steps.append(
                {"step": "knowledge_generation", "result": contextual_knowledge}
            )

            # 5. Análisis de errores potenciales
            error_analysis = self._analyze_potential_errors(adapted_query)
            processing_steps.append({"step": "error_analysis", "result": error_analysis})

            # 6. Registro para mejora continua
            self._log_interaction(query, adapted_query, routing_result)

            # Resultado final
            result = {
                "success": True,
                "original_query": query,
                "adapted_query": adapted_query,
                "routing": routing_result,
                "contextual_knowledge": contextual_knowledge,
                "error_analysis": error_analysis,
                "processing_steps": processing_steps,
                "confidence": self._calculate_confidence(processing_steps),
                "timestamp": datetime.now().isoformat(),
            }

            return result

        except Exception as e:
            self.logger.error(f"Error procesando consulta: {e}")
            return {
                "error": f"Error procesando consulta: {str(e)}",
                "query": query,
                "timestamp": datetime.now().isoformat(),
            }

    def _validate_security(self, query: str) -> Dict[str, Any]:
        """Validación de seguridad simplificada"""
        # Validaciones básicas
        if len(query) > 10000:
            return {"valid": False, "reason": "Query too long"}

        # Lista de patrones peligrosos (básica)
        dangerous_patterns = ["<script>", "DROP TABLE", "DELETE FROM", "INSERT INTO"]
        for pattern in dangerous_patterns:
            if pattern.lower() in query.lower():
                return {
                    "valid": False,
                    "reason": f"Dangerous pattern detected: {pattern}",
                }

        return {"valid": True, "reason": "Security check passed"}

    def _adapt_semantic_context(self, query: str) -> str:
        """Adaptación semántica básica"""
        # Normalización simple
        adapted = query.strip()

        # Correcciones comunes
        replacements = {"q es": "qué es", "xq": "por qué", "pq": "por qué"}

        for old, new in replacements.items():
            adapted = adapted.replace(old, new)

        return adapted

    def _route_query(self, query: str) -> Dict[str, Any]:
        """Enrutamiento de consulta simplificado"""
        query_lower = query.lower()

        # Clasificación por palabras clave
        if any(word in query_lower for word in ["python", "código", "programar", "función"]):
            domain = "programming"
        elif any(
            word in query_lower
            for word in ["ia", "inteligencia artificial", "machine learning", "modelo"]
        ):
            domain = "ai"
        elif any(word in query_lower for word in ["base de datos", "sql", "database"]):
            domain = "database"
        else:
            domain = "general"

        return {
            "domain": domain,
            "confidence": 0.8,
            "route_type": "semantic",
            "keywords_found": [word for word in ["python", "ia", "sql"] if word in query_lower],
        }

    def _generate_contextual_knowledge(self, query: str, domain: str) -> Dict[str, Any]:
        """Generar conocimiento contextual"""
        try:
            # Intentar usar DynamicKnowledgeGenerator si está disponible
            try:
                # Primero intentar desde sheily_core
                from sheily_core.tools.merger import BranchMerger

                # Usar el merger como generador de conocimiento contextual
                knowledge = {
                    "domain": domain,
                    "context": query,
                    "suggestions": [
                        f"Explorar más sobre {domain}",
                        "Considerar ejemplos prácticos",
                    ],
                    "confidence": 0.7,
                    "source": "sheily_core_merger",
                }
                return knowledge
            except ImportError:
                # Fallback: intentar desde modules (estructura legacy)
                from modules.core.dynamic_knowledge_generator import DynamicKnowledgeGenerator

                generator = DynamicKnowledgeGenerator()
                knowledge = generator.generate_contextual_knowledge(query, domain)
                return knowledge

        except Exception as e:
            self.logger.error(f"Error generando conocimiento: {e}")
            return {
                "domain": domain,
                "context": query,
                "error": str(e),
                "fallback_knowledge": {
                    "suggestions": [f"Explorar más sobre {domain}"],
                    "confidence": 0.5,
                },
            }

    def _analyze_potential_errors(self, query: str) -> Dict[str, Any]:
        """Análisis de errores potenciales"""
        potential_issues = []

        # Verificar longitud
        if len(query) < 3:
            potential_issues.append("Query muy corta")

        # Verificar caracteres especiales
        special_chars = set(query) & set("@#$%^&*(){}[]|\\")
        if special_chars:
            potential_issues.append(f"Caracteres especiales detectados: {special_chars}")

        # Verificar idioma (básico)
        spanish_words = [
            "el",
            "la",
            "de",
            "que",
            "y",
            "a",
            "en",
            "un",
            "es",
            "se",
            "no",
            "te",
            "lo",
            "le",
        ]
        word_count = len(query.split())
        spanish_word_count = sum(1 for word in query.lower().split() if word in spanish_words)

        if word_count > 0:
            spanish_ratio = spanish_word_count / word_count
            if spanish_ratio < 0.2:
                potential_issues.append("Posible idioma no español")

        return {
            "issues_found": potential_issues,
            "risk_level": "high" if len(potential_issues) > 2 else "low",
            "recommendations": (["Verificar entrada del usuario"] if potential_issues else []),
        }

    def _calculate_confidence(self, processing_steps: List[Dict]) -> float:
        """Calcular confianza general del procesamiento"""
        if not processing_steps:
            return 0.0

        # Calcular confianza basada en los pasos exitosos
        successful_steps = sum(
            1
            for step in processing_steps
            if isinstance(step.get("result"), dict) and not step["result"].get("error")
        )
        total_steps = len(processing_steps)

        base_confidence = successful_steps / total_steps if total_steps > 0 else 0.0

        # Ajustar por factores específicos
        for step in processing_steps:
            step_result = step.get("result")
            if not isinstance(step_result, dict):
                continue

            if step["step"] == "security" and not step_result.get("valid", True):
                base_confidence *= 0.5
            elif step["step"] == "routing":
                routing_confidence = step_result.get("confidence", 0.5)
                base_confidence = (base_confidence + routing_confidence) / 2

        return min(base_confidence, 1.0)

    def _log_interaction(self, original_query: str, adapted_query: str, routing_result):
        """Registrar interacción para mejora continua"""
        # Asegurar que routing_result es un diccionario
        if isinstance(routing_result, dict):
            domain = routing_result.get("domain")
            confidence = routing_result.get("confidence")
        else:
            # Si no es un dict, usar valores por defecto
            domain = "general"
            confidence = 0.5

        interaction = {
            "timestamp": datetime.now().isoformat(),
            "original_query": original_query,
            "adapted_query": adapted_query,
            "domain": domain,
            "confidence": confidence,
        }

        self.integration_history.append(interaction)

        # Mantener solo las últimas 100 interacciones
        if len(self.integration_history) > 100:
            self.integration_history = self.integration_history[-100:]

    def get_system_status(self) -> Dict[str, Any]:
        """Obtener estado del sistema"""
        return {
            "initialized": self.initialized,
            "active_modules": self.active_modules,
            "module_health": self.module_health,
            "config": self.effective_config,
            "interaction_count": len(self.integration_history),
            "last_interaction": (
                self.integration_history[-1] if self.integration_history else None
            ),
            "timestamp": datetime.now().isoformat(),
        }

    def health_check(self) -> Dict[str, Any]:
        """Verificación de salud del sistema"""
        health_status = {"overall_health": "good", "issues": [], "modules": {}}

        # Verificar cada módulo
        for module_name, module_info in self.active_modules.items():
            module_health = module_info.get("health", "unknown")
            health_status["modules"][module_name] = module_health

            if module_health != "good":
                health_status["issues"].append(f"Módulo {module_name}: {module_health}")

        # Determinar salud general
        if health_status["issues"]:
            health_status["overall_health"] = (
                "degraded" if len(health_status["issues"]) < 3 else "poor"
            )

        health_status["timestamp"] = datetime.now().isoformat()
        return health_status

    def train_and_improve(self):
        """Entrenar y mejorar el sistema"""
        self.logger.info("Iniciando proceso de mejora continua...")

        if not self.integration_history:
            self.logger.warning("No hay historial de interacciones para analizar")
            return

        # Análisis básico del historial
        domain_counts = {}
        confidence_scores = []

        for interaction in self.integration_history:
            domain = interaction.get("domain", "unknown")
            domain_counts[domain] = domain_counts.get(domain, 0) + 1

            confidence = interaction.get("confidence", 0.0)
            if confidence > 0:
                confidence_scores.append(confidence)

        # Estadísticas
        avg_confidence = (
            sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
        )
        most_common_domain = (
            max(domain_counts, key=domain_counts.get) if domain_counts else "unknown"
        )

        self.logger.info(f"Análisis de mejora: Confianza promedio: {avg_confidence:.2f}")
        self.logger.info(f"Dominio más común: {most_common_domain}")

        # Actualizar configuración basada en análisis
        if avg_confidence < 0.7:
            self.logger.warning("Confianza promedio baja, ajustando parámetros")
            self.effective_config["require_higher_confidence"] = True
