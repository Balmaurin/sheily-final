# Sheily Core - Integration Layer
## Servicios y APIs de Integraci칩n

### 游꿢 Prop칩sito
La capa de integraci칩n proporciona servicios API y conectores para unir todos los componentes de Sheily AI en un sistema cohesivo.

### 游댢 Componentes Principales

#### 游깷 Web Chat Server (`web_chat_server.py`)
**API REST completa para chat con RAG**

- **Endpoints**:
  - `GET /health` - Estado del sistema
  - `POST /chat` - Consulta con RAG integrado

- **Caracter칤sticas**:
  - Soporte m칰ltiple LLM (Ollama, llama.cpp)
  - RAG opcional por consulta
  - Rate limiting y seguridad
  - Logging estructurado

```python
# Uso b치sico
from sheily_core.integration.web_chat_server import app

# El servidor se inicia autom치ticamente con:
# python -m sheily_core.integration.web_chat_server
```

#### 游뱄 RAG Service (`rag_service.py`)
**Servicio dedicado de Retrieval Augmented Generation**

- **Arquitectura FAISS**: B칰squeda vectorial ultrarr치pida
- **Embeddings multiling칲es**: Soporte espa침ol/ingl칠s nativo
- **API REST completa**:
  - `POST /process_corpus` - Indexar documentos
  - `POST /add_document` - Agregar documento individual
  - `POST /search` - Buscar similitud sem치ntica
  - `GET /health` - Estado del servicio

```python
from sheily_core.integration.rag_service import RAGService

service = RAGService()
await service.initialize()  # Carga modelo de embeddings
```

#### 游댕 RAG Client (`rag_client.py`)
**Cliente HTTP para conectar con RAG Service**

- **Integraci칩n transparente**: Funciona como puente HTTP
- **Fallback inteligente**: Maneja desconexiones graceful
- **Cache autom치tico**: Optimiza performance

```python
from sheily_core.integration.rag_client import get_rag_context

# Obtener contexto RAG para una consulta
context, chunks = get_rag_context("쯈u칠 es la antropolog칤a?", max_length=2000)
```

### 游 Inicio de Servicios

#### Opci칩n 1: Todo autom치tico (Recomendado)
```bash
python quick_start.py
```
Inicia RAG Service + Chat Server simult치neamente.

#### Opci칩n 2: Servicios individuales
```bash
# Terminal 1: RAG Service
python start_rag_service.py

# Terminal 2: Chat Server
python -m sheily_core.integration.web_chat_server
```

#### Opci칩n 3: Desarrollo manual
```python
# RAG Service standalone
from sheily_core.integration.rag_service import main
import asyncio
asyncio.run(main())

# Chat Server standalone
uvicorn sheily_core.integration.web_chat_server:app --host 0.0.0.0 --port 8000
```

### 游니 APIs Externas Integradas

#### Ollama Client (`ollama_client.py`)
```python
from sheily_core.integration.ollama_client import generate_completion

response = await generate_completion(
    prompt="쯈u칠 es la IA?",
    model="llama3.2",
    options={"temperature": 0.7}
)
```

#### Llama.cpp Client (`llama_cpp_client.py`)
```python
from sheily_core.integration.llama_cpp_client import generate_completion

response = generate_completion(
    prompt="Explica machine learning",
    model_path="/path/to/model.gguf",
    max_tokens=512
)
```

### 游댢 Configuraci칩n

#### Variables de Entorno
```bash
# URLs de servicios
SHEILY_RAG_SERVICE_URL=http://localhost:8001
SHEILY_CHAT_PORT=8000

# LLM Provider
SHEILY_LLM_PROVIDER=ollama  # o llama_cpp

# Modelo llama.cpp
SHEILY_LLAMA_MODEL_PATH=/path/to/model.gguf

# Seguridad
SHEILY_MCP_ENABLED=true
```

#### Configuraci칩n Program치tica
```python
from sheily_core.integration.rag_client import initialize_rag_service

# Inicializar con URL personalizada
success = initialize_rag_service("http://localhost:8001")
if not success:
    print("RAG Service no disponible")
```

### 游빍 Testing de Integraci칩n

```bash
# Tests unitarios
pytest tests/unit/ -v

# Tests de integraci칩n
pytest tests/integration/ -v

# Tests de API
pytest tests/integration/test_rag_api.py -v

# Tests de seguridad
pytest tests/security/ -v

# Tests de performance
pytest tests/performance/ -v
```

### 游늵 Monitoreo y Health Checks

#### Health Check Completo
```bash
# Verificar estado de todos los servicios
curl http://localhost:8000/health  # Chat Service
curl http://localhost:8001/health  # RAG Service
```

#### M칠tricas de Performance
- **Latencia**: <100ms para b칰squedas RAG
- **Throughput**: >100 consultas/minuto
- **Disponibilidad**: 99.9% uptime esperado
- **Memoria**: <500MB para servicios completos

### 游 Seguridad Integrada

#### Autenticaci칩n
- JWT opcional para APIs
- Rate limiting autom치tico
- Validaci칩n de entrada

#### Auditor칤a
- Logs estructurados completos
- Trazabilidad de consultas
- Monitoreo de seguridad en tiempo real

### 游댃 Escalabilidad

#### Arquitectura de Microservicios
- **Independiente**: Cada servicio puede escalar por separado
- **Stateless**: Los servicios no mantienen estado entre llamadas
- **Load Balancing**: F치cil distribuci칩n de carga

#### Optimizaciones
- **Cache inteligente**: Resultados de b칰squedas frecuentes
- **Async/Await**: Procesamiento no bloqueante
- **Pooling de conexiones**: Optimizaci칩n de recursos

### 游뚿 Troubleshooting

#### Problema: "RAG Service no disponible"
```bash
# Verificar que est치 ejecut치ndose
curl http://localhost:8001/health

# Reiniciar servicio
python start_rag_service.py
```

#### Problema: "Connection refused"
```bash
# Verificar puertos
netstat -ano | findstr :8001
netstat -ano | findstr :8000

# Cambiar puertos si hay conflictos
export SHEILY_RAG_SERVICE_URL=http://localhost:8003
export SHEILY_CHAT_PORT=8004
```

#### Problema: "Timeout en consultas"
```bash
# Verificar recursos del sistema
top  # o Task Manager

# Reducir carga o aumentar timeouts
# en configuraci칩n del servicio
```

### 游꿢 Mejores Pr치cticas

1. **Inicio ordenado**: Siempre RAG Service antes que Chat Server
2. **Health checks**: Verificar estado antes de usar APIs
3. **Timeouts apropiados**: Configurar timeouts seg칰n carga esperada
4. **Logging**: Monitorear logs para debugging
5. **Backup**: Mantener backups del 칤ndice FAISS

### 游댩 Evoluci칩n Futura

- **GraphQL**: API m치s flexible y eficiente
- **WebSockets**: Comunicaci칩n en tiempo real
- **Kubernetes**: Orquestaci칩n nativa
- **Multi-tenancy**: Aislamiento por usuario/organizaci칩n
- **API Gateway**: Punto 칰nico de entrada centralizado
